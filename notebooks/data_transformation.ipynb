{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edd2aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path= os.getcwd()\n",
    "\n",
    "if path.endswith('notebooks'):\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f50ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a231caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file content: {'artifacts_root': 'artifacts', 'data_ingestion': {'data_ingestion_dir': 'artifacts/data_ingestion', 'test_data_url': 'https://drive.google.com/file/d/1Dy1CmtS30nSa2lxgBr-VK_ufMz7AXpV9', 'train_data_url': 'https://drive.google.com/file/d/1dYWh2YlTwtbnPbN6bcOOJgR011W0fWwx', 'train_data_path': 'artifacts/data_ingestion/raw_data', 'test_data_path': 'artifacts/data_ingestion/raw_data'}, 'data_validation': {'data_validation_dir': 'artifacts/data_validation', 'train_data_path': 'artifacts/data_ingestion/raw_data/home_insurance_train.csv', 'status_file': 'artifacts/data_validation/status.txt'}, 'data_transformation': {'data_transformation_dir': 'artifacts/data_transformation', 'train_data_path': 'artifacts/data_ingestion/raw_data/home_insurance_train.csv', 'processed_data_path': 'artifacts/data_transformation/transformed_data'}}\n",
      "Data Transformation Dir: artifacts/data_transformation\n",
      "created directory at: artifacts/data_transformation\n",
      "Shape mismatch: 32 != 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from src.Home_Premium_Prediction.utils import create_directories, read_yaml\n",
    "from src.Home_Premium_Prediction.constants import CONFIG_FILE_PATH\n",
    "\n",
    "class DataTransfromationConfig:\n",
    "    def __init__(self, data_transformation_dir: Path, train_data_path: Path, processed_data_path: Path):\n",
    "        self.data_transformation_dir = data_transformation_dir\n",
    "        self.train_data_path = train_data_path\n",
    "        self.processed_data_path = processed_data_path\n",
    "\n",
    "class DataTransformationConfigManager:\n",
    "    def __init__(self, config_file=CONFIG_FILE_PATH):\n",
    "        self.config_file = read_yaml(config_file)\n",
    "        print(f\"Config file content: {self.config_file}\")  # Debugging line\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransfromationConfig:\n",
    "        # Print the config paths\n",
    "        print(f\"Data Transformation Dir: {self.config_file['data_transformation']['data_transformation_dir']}\")\n",
    "        create_directories([self.config_file['data_transformation']['data_transformation_dir']])\n",
    "        return DataTransfromationConfig(\n",
    "            data_transformation_dir=self.config_file['data_transformation']['data_transformation_dir'],\n",
    "            train_data_path=self.config_file['data_transformation']['train_data_path'],\n",
    "            processed_data_path=self.config_file['data_transformation']['processed_data_path']\n",
    "        )\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransfromationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def run(self):\n",
    "        df = pd.read_csv(self.config.train_data_path)\n",
    "        df.drop(columns=['uuid', 'quote_id'], inplace=True)\n",
    "\n",
    "        target = df['Premium']\n",
    "        df.drop(columns=['Premium'], inplace=True)\n",
    "\n",
    "        # Define column types\n",
    "        nominal_cols = ['property_type', 'broker_name', 'ownership_status']\n",
    "        ordinal_cols = ['coverage_level', 'energy_efficiency_rating']\n",
    "        high_cardinality_col = ['pcd']\n",
    "        uniform_cols = ['year_built', 'building_value', 'contents_value', 'flood_risk_score',\n",
    "                        'fire_risk_score', 'crime_rate_score', 'distance_to_fire_station']\n",
    "        normal_cols = ['long', 'lat']\n",
    "\n",
    "        # Ordinal mappings\n",
    "        ordinal_mapping = [['Gold', 'Silver', 'Platinum', 'Bronze'],  # coverage_level\n",
    "                           ['A', 'B', 'C', 'D', 'E']]                  # energy_efficiency_rating\n",
    "\n",
    "        # High cardinality encoding (frequency)\n",
    "        df['pcd'] = df['pcd'].map(df['pcd'].value_counts() / len(df))\n",
    "\n",
    "        # Pipelines\n",
    "        nominal_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        ordinal_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ordinal', OrdinalEncoder(categories=ordinal_mapping))\n",
    "        ])\n",
    "\n",
    "        uniform_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('minmax', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "        normal_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('std', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            ('nominal', nominal_pipeline, nominal_cols),\n",
    "            ('ordinal', ordinal_pipeline, ordinal_cols),\n",
    "            ('uniform', uniform_pipeline, uniform_cols),\n",
    "            ('normal', normal_pipeline, normal_cols)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "        # Fit and transform\n",
    "        processed_features = preprocessor.fit_transform(df)\n",
    "\n",
    "        # Column names after transformation\n",
    "        nominal_encoded = preprocessor.named_transformers_['nominal'].named_steps['onehot'].get_feature_names_out(nominal_cols)\n",
    "        ordinal_encoded = ordinal_cols  # OrdinalEncoder does not change names\n",
    "        uniform_encoded = uniform_cols  # MinMaxScaler doesn't change names\n",
    "        normal_encoded = normal_cols    # StandardScaler doesn't change names\n",
    "        remainder_encoded = ['pcd']     # manually encoded\n",
    "\n",
    "        final_columns = list(nominal_encoded) + ordinal_encoded + uniform_encoded + normal_encoded + remainder_encoded\n",
    "\n",
    "        # Make sure shapes match\n",
    "        assert processed_features.shape[1] == len(final_columns), f\"Shape mismatch: {processed_features.shape[1]} != {len(final_columns)}\"\n",
    "\n",
    "        # Save as DataFrame\n",
    "        X_df = pd.DataFrame(processed_features, columns=final_columns)\n",
    "        y_df = pd.DataFrame(target, columns=['Premium'])\n",
    "\n",
    "        output_dir = Path(self.config.processed_data_path)\n",
    "        create_directories([output_dir])\n",
    "\n",
    "        X_df.to_csv(output_dir / 'preprocessed_features.csv', index=False)\n",
    "        y_df.to_csv(output_dir / 'preprocessed_target.csv', index=False)\n",
    "\n",
    "        print(\"✅ Preprocessing complete. Files saved.\")\n",
    "\n",
    "\n",
    "# ✅ Main runner\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config = DataTransformationConfigManager().get_data_transformation_config()\n",
    "        transformer = DataTransformation(config)\n",
    "        transformer.run()\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b903dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
